name: AI Agent Pipeline

on:
  pull_request:
    types: [opened, synchronize, reopened]
  workflow_dispatch:
    inputs:
      pr_number:
        description: 'PR number to analyze (or "all" for all open PRs)'
        required: true
        type: string
        default: 'all'
      agents:
        description: 'Agents to run (comma-separated: validator,remediator,guardian,verifier or "all")'
        required: false
        default: 'all'
        type: string

permissions:
  pull-requests: write
  contents: read
  issues: write

jobs:
  # Job 1: Collect target PRs
  collect-prs:
    name: Collect Target PRs
    runs-on: ubuntu-latest
    outputs:
      pr_numbers: ${{ steps.get-prs.outputs.pr_numbers }}
    steps:
      - name: Get PR numbers
        id: get-prs
        uses: actions/github-script@v7
        with:
          script: |
            let prNumbers = [];
            
            if (context.eventName === 'pull_request') {
              // Triggered by PR event
              prNumbers = [context.payload.pull_request.number];
            } else if (context.eventName === 'workflow_dispatch') {
              const input = '${{ inputs.pr_number }}';
              
              if (input.toLowerCase() === 'all') {
                // Fetch all open PRs
                console.log('Fetching all open PRs...');
                const { data: pullRequests } = await github.rest.pulls.list({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  state: 'open',
                  per_page: 100
                });
                
                prNumbers = pullRequests.map(pr => pr.number);
                console.log(`Found ${prNumbers.length} open PRs: ${prNumbers.join(', ')}`);
              } else {
                // Single PR number
                prNumbers = [parseInt(input)];
              }
            }
            
            // Output as JSON array
            core.setOutput('pr_numbers', JSON.stringify(prNumbers));
      
      - name: Show target PRs
        run: |
          echo "Target PRs: ${{ steps.get-prs.outputs.pr_numbers }}"

  # Job 2: Run agents in parallel using matrix strategy
  run-agents:
    name: ${{ matrix.agent }} (PR ${{ matrix.pr }})
    runs-on: ubuntu-latest
    environment: METASERVER  # Access environment secrets
    needs: collect-prs
    if: needs.collect-prs.outputs.pr_numbers != '[]'
    
    strategy:
      fail-fast: false
      matrix:
        pr: ${{ fromJson(needs.collect-prs.outputs.pr_numbers) }}
        agent:
          - validator
          - remediator
          - guardian
          - verifier
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pyyaml httpx
          # Install project dependencies if needed
          if [ -f pyproject.toml ]; then
            pip install -e .
          fi
      
      - name: Verify environment
        run: |
          echo "=== Python Version ==="
          python --version
          
          echo "=== Installed Packages ==="
          pip list | grep -E "(httpx|pyyaml)"
          
          echo "=== Import Test ==="
          python -c "import httpx; import yaml; print('âœ… Imports successful')"
          
          echo "=== Environment Variables Check ==="
          echo "GITHUB_TOKEN: ${GITHUB_TOKEN:+SET}"
          echo "AZURE_OPENAI_API_KEY: ${AZURE_OPENAI_API_KEY:+SET}"
          echo "MODELS_API_TOKEN: ${MODELS_API_TOKEN:+SET}"
          echo "MOONSHOT_API_KEY: ${MOONSHOT_API_KEY:+SET}"
          echo "OPENROUTER_API_KEY: ${OPENROUTER_API_KEY:+SET}"
      
      - name: Run ${{ matrix.agent }} agent
        id: run-agent
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          # Azure OpenAI (for validator)
          AZURE_OPENAI_API_KEY: ${{ secrets.AZURE_OPENAI_API_KEY }}
          # GitHub Models (for remediator)
          MODELS_API_TOKEN: ${{ secrets.MODELS_API_TOKEN }}
          # Moonshot (for guardian)
          MOONSHOT_API_KEY: ${{ secrets.MOONSHOT_API_KEY }}
          # OpenRouter (for verifier)
          OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY }}
        run: |
          set +e  # Don't exit on error immediately
          mkdir -p results
          
          echo "=== Running ${{ matrix.agent }} agent on PR ${{ matrix.pr }} ==="
          
          python -m scripts.agents.run_agent \
            --pr ${{ matrix.pr }} \
            --agent ${{ matrix.agent }} \
            --output results/${{ matrix.agent }}_pr${{ matrix.pr }}.json 2>&1 | tee agent_error.log
          
          exit_code=$?
          
          if [ $exit_code -ne 0 ]; then
            echo "âŒ Agent failed with exit code: $exit_code"
            echo "=== Error Log ==="
            cat agent_error.log
            
            # Create error result file
            error_msg=$(cat agent_error.log | head -n 100 | jq -Rs .)
            cat > results/${{ matrix.agent }}_pr${{ matrix.pr }}.json << EOF
          {
            "agent": "${{ matrix.agent }}",
            "pr": ${{ matrix.pr }},
            "verdict": "ERROR",
            "summary": "Agent execution failed - see workflow logs for details",
            "error": "Exit code: $exit_code",
            "error_log": $error_msg,
            "findings": []
          }
          EOF
            echo "âœ… Created error result file"
          fi
        continue-on-error: true
      
      - name: Upload results
        uses: actions/upload-artifact@v4.4.3
        if: always()
        with:
          name: ${{ matrix.agent }}-pr${{ matrix.pr }}-results
          path: results/${{ matrix.agent }}_pr${{ matrix.pr }}.json
          retention-days: 30

  # Job 3: Generate summary report
  generate-summary:
    name: Generate Summary Report
    runs-on: ubuntu-latest
    needs: [collect-prs, run-agents]
    if: always() && needs.collect-prs.outputs.pr_numbers != '[]'
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Download all results
        uses: actions/download-artifact@v4.1.3
        with:
          path: results/
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
      
      - name: Generate summary
        run: |
          python << 'PYTHON_SCRIPT'
          import json
          import os
          from pathlib import Path
          
          # Find all result files
          results_dir = Path("results")
          all_results = {}
          
          # Handle case where results directory doesn't exist or is empty
          if not results_dir.exists():
              print("âš ï¸ No results directory found - all agents may have failed")
              summary = "# ðŸ¤– AI Agent Pipeline Results\n\n"
              summary += "âš ï¸ **Warning**: No results directory found. All agents may have failed to execute.\n"
              summary += "\nCheck individual job logs for details.\n"
              with open(os.environ["GITHUB_STEP_SUMMARY"], "w") as f:
                  f.write(summary)
              print(summary)
              exit(0)
          
          # Check if directory is empty
          if not any(results_dir.iterdir()):
              print("âš ï¸ Results directory is empty - no artifacts were uploaded")
              summary = "# ðŸ¤– AI Agent Pipeline Results\n\n"
              summary += "âš ï¸ **Warning**: No agent results were uploaded.\n"
              summary += "\nCheck individual job logs for details.\n"
              with open(os.environ["GITHUB_STEP_SUMMARY"], "w") as f:
                  f.write(summary)
              print(summary)
              exit(0)
          
          for artifact_dir in results_dir.iterdir():
              if artifact_dir.is_dir():
                  for result_file in artifact_dir.glob("*.json"):
                      try:
                          with open(result_file) as f:
                              data = json.load(f)
                              # Parse filename: agent_prNNN.json
                              filename = result_file.stem  # e.g., "validator_pr123"
                              if "_pr" in filename:
                                  parts = filename.split("_pr")
                                  agent_name = parts[0]
                                  pr_num = parts[1]
                              else:
                                  # Fallback for unexpected format
                                  agent_name = filename.split("_")[0]
                                  pr_num = filename.split("pr")[1] if "pr" in filename else "unknown"
                              
                              if pr_num not in all_results:
                                  all_results[pr_num] = {}
                              all_results[pr_num][agent_name] = data
                      except Exception as e:
                          print(f"âš ï¸ Failed to parse {result_file}: {e}")
          
          # Generate markdown summary
          summary = "# ðŸ¤– AI Agent Pipeline Results\n\n"
          
          if not all_results:
              summary += "âš ï¸ **Warning**: No valid results found.\n"
              summary += "\nCheck individual job logs for details.\n"
          
          for pr_num, agents in sorted(all_results.items()):
              summary += f"## PR #{pr_num}\n\n"
              summary += "| Agent | Verdict | Summary |\n"
              summary += "|-------|---------|----------|\n"
              
              for agent_name, result in sorted(agents.items()):
                  verdict = result.get("verdict", "UNKNOWN")
                  emoji = {"PASS": "âœ…", "WARN": "âš ï¸", "FAIL": "âŒ", "BLOCK": "ðŸš«", "ERROR": "ðŸ’¥"}.get(verdict, "â“")
                  agent_display = agent_name.title()
                  summary_text = result.get("summary", "No summary")[:100]
                  
                  summary += f"| {emoji} {agent_display} | {verdict} | {summary_text} |\n"
              
              summary += "\n"
          
          # Write to GitHub Step Summary
          with open(os.environ["GITHUB_STEP_SUMMARY"], "w") as f:
              f.write(summary)
          
          print(summary)
          PYTHON_SCRIPT
      
      - name: Upload combined results
        uses: actions/upload-artifact@v4.4.3
        with:
          name: ai-agent-pipeline-results
          path: results/
          retention-days: 90

  # Job 4: Check overall status
  check-status:
    name: Check Overall Status
    runs-on: ubuntu-latest
    needs: [run-agents]
    if: always()
    
    steps:
      - name: Download all results
        uses: actions/download-artifact@v4.1.3
        with:
          path: results/
      
      - name: Check for blocking issues
        run: |
          python << 'PYTHON_SCRIPT'
          import json
          import sys
          from pathlib import Path
          
          # Find all result files
          results_dir = Path("results")
          has_block = False
          has_fail = False
          has_error = False
          
          # Handle missing results directory
          if not results_dir.exists():
              print("âš ï¸ No results directory found - treating as error state")
              sys.exit(1)
          
          # Handle empty directory
          if not any(results_dir.iterdir()):
              print("âš ï¸ No results found - treating as error state")
              sys.exit(1)
          
          for artifact_dir in results_dir.iterdir():
              if artifact_dir.is_dir():
                  for result_file in artifact_dir.glob("*.json"):
                      try:
                          with open(result_file) as f:
                              data = json.load(f)
                              verdict = data.get("verdict", "")
                              
                              if verdict == "BLOCK":
                                  has_block = True
                                  print(f"ðŸš« BLOCK found in {result_file.name}")
                              elif verdict == "FAIL":
                                  has_fail = True
                                  print(f"âŒ FAIL found in {result_file.name}")
                              elif verdict == "ERROR" or "error" in data:
                                  has_error = True
                                  print(f"âš ï¸ ERROR found in {result_file.name}")
                      except json.JSONDecodeError as e:
                          print(f"âš ï¸ Could not parse {result_file.name}: {e}")
                          has_error = True
                      except Exception as e:
                          print(f"âš ï¸ Error reading {result_file.name}: {e}")
                          has_error = True
          
          if has_block:
              print("\nðŸš« BLOCKING ISSUES FOUND - PR should not be merged")
              sys.exit(2)
          elif has_fail or has_error:
              print("\nâŒ FAILURES FOUND - Review required")
              sys.exit(1)
          else:
              print("\nâœ… All agents passed")
              sys.exit(0)
          PYTHON_SCRIPT
